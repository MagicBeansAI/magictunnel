# MagicTunnel Production Configuration
# This is the default configuration file (magictunnel-config.yaml)
# All settings can be overridden via environment variables
#
# IMPORTANT: Legacy mcp_proxy, mcp_servers, and remote_mcp configurations have been removed.
# Use the new external_mcp system for connecting to external MCP servers.

# =============================================================================
# DEPLOYMENT CONFIGURATION (v0.3.10)
# =============================================================================
# Multi-mode architecture configuration - defaults to advanced mode for production
deployment:
  runtime_mode: "advanced"       # Runtime mode: "proxy"|"advanced" (env: MAGICTUNNEL_RUNTIME_MODE)
                                  # Advanced mode provides full enterprise features

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
server:
  host: "0.0.0.0"        # Server bind address (env: MCP_HOST)
  port: 3001              # Server port 1-65535 (env: MCP_PORT)
                           # Note: gRPC server automatically runs on port + 1000 (e.g., 4000)
  websocket: true          # Enable WebSocket support (env: MCP_WEBSOCKET)
  timeout: 30              # Request timeout in seconds (env: MCP_TIMEOUT)

  # TLS/SSL Configuration (Optional)
  tls:
    mode: "disabled"       # TLS mode: disabled|application|behind_proxy|auto
    cert_file: null        # Path to certificate file (PEM format)
    key_file: null         # Path to private key file (PEM format)
    ca_file: null          # Path to CA certificate file (optional)
    behind_proxy: false    # Whether running behind a reverse proxy
    trusted_proxies:       # List of trusted proxy IP ranges (CIDR notation)
      - "10.0.0.0/8"
      - "172.16.0.0/12"
      - "192.168.0.0/16"
      - "127.0.0.1/32"
    min_tls_version: "1.2" # Minimum TLS version (1.2, 1.3)
    cipher_suites: null    # Custom cipher suites (optional)
    hsts_enabled: true     # Enable HTTP Strict Transport Security (HSTS)
    hsts_max_age: 31536000 # HSTS max age in seconds (1 year)
    hsts_include_subdomains: false
    hsts_preload: false
    require_forwarded_proto: false
    require_forwarded_for: false
    auto_detect_headers:   # Auto-detection headers to check
      - "X-Forwarded-Proto"
      - "X-Forwarded-For"
      - "X-Real-IP"
    fallback_mode: "application"

# =============================================================================
# CAPABILITY REGISTRY CONFIGURATION
# =============================================================================
registry:
  type: "file"             # Registry type: "file" (env: MCP_REGISTRY_TYPE)
  paths:                   # Paths to scan for capability files (env: MCP_REGISTRY_PATHS)
    - "/Users/gouravd/Development/magicbeanbs100x/magictunnel/capabilities"     # Default capabilities directory
                           # Note: External capabilities are auto-generated by external_mcp discovery
  hot_reload: true         # Enable file watching for changes (env: MCP_HOT_RELOAD)
  validation:
    strict: true           # Strict validation mode
    allow_unknown_fields: false



# =============================================================================
# AUTHENTICATION CONFIGURATION
# =============================================================================
# MagicTunnel supports comprehensive OAuth 2.1 multi-level authentication
# with hierarchical Server ‚Üí Capability ‚Üí Tool authentication resolution.
# All four authentication methods are supported: OAuth 2.1, Device Code Flow, API Keys, and Service Accounts.

# SIMPLE AUTHENTICATION EXAMPLES (uncomment to enable):
# 
# Simple API Key Authentication:
# auth:
#   enabled: true
#   type: "api_key"
#   api_keys:
#     - key_ref: "admin_key"
#       name: "Admin Key"
#       key: "your_secure_api_key_here_min_16_chars"
#       rbac_roles: ["read", "write", "admin"]
#       active: true
#       expires_at: "2025-12-31T23:59:59Z"
#     - key_ref: "readonly_key"
#       name: "Read Only Key"
#       key: "readonly_key_here_min_16_chars"
#       rbac_roles: ["read"]
#       active: true
#
# Simple OAuth Authentication:
# auth:
#   enabled: true
#   type: "oauth"
#   oauth_providers:
#     github:
#       client_id: "${GITHUB_CLIENT_ID}"
#       client_secret: "${GITHUB_CLIENT_SECRET}"
#       scopes: ["user:email"]
#       oauth_enabled: true
#       authorization_endpoint: "https://github.com/login/oauth/authorize"
#       token_endpoint: "https://github.com/login/oauth/access_token"
#       user_info_endpoint: "https://api.github.com/user"

# COMPLETE OAUTH 2.1 MULTI-LEVEL AUTHENTICATION (Advanced Configuration)
# Uncomment and customize the complete OAuth 2.1 configuration below for enterprise features:
#
# auth:
#   enabled: true
#   type: "multi_level"                    # Enable advanced multi-level authentication
#   
#   # Multi-level authentication hierarchy (Server ‚Üí Capability ‚Üí Tool)
#   multi_level:
#     enabled: true
#     
#     # Server-level authentication (applies to all tools unless overridden)
#     server_level:
#       type: "oauth"                      # oauth|device_code|api_key|service_account
#       provider: "github"
#       scopes: ["user:email"]
#     
#     # Capability-level authentication overrides
#     capabilities:
#       github:
#         type: "api_key"
#         key_ref: "github_api_key"
#       google:
#         type: "device_code"
#         provider: "google"
#         scopes: ["https://www.googleapis.com/auth/userinfo.email"]
#     
#     # Tool-level authentication overrides (highest priority)
#     tools:
#       github_create_issue:
#         type: "device_code"
#         provider: "github" 
#         scopes: ["repo"]
#       google_sheets_read:
#         type: "service_account"
#         account_ref: "google_service"
# 
#   # OAuth Provider Configurations (with Device Code Flow support)
#   oauth_providers:
#     github:
#       client_id: "${GITHUB_CLIENT_ID}"
#       client_secret: "${GITHUB_CLIENT_SECRET}"
#       scopes: ["user:email", "repo", "read:org"]
#       oauth_enabled: true                # Enable standard OAuth 2.1 flow
#       device_code_enabled: true          # Enable Device Code Flow (RFC 8628)
#       authorization_endpoint: "https://github.com/login/oauth/authorize"
#       device_authorization_endpoint: "https://github.com/login/device/code"
#       token_endpoint: "https://github.com/login/oauth/access_token"
#       user_info_endpoint: "https://api.github.com/user"
#       resource_indicators: 
#         - "urn:magictunnel:mcp:github:*"
#         - "https://api.github.com/*"
#       extra_params:
#         allow_signup: "false"
#         
#     google:
#       client_id: "${GOOGLE_CLIENT_ID}"
#       client_secret: "${GOOGLE_CLIENT_SECRET}"
#       scopes: ["openid", "email", "profile", "https://www.googleapis.com/auth/spreadsheets"]
#       oauth_enabled: true
#       device_code_enabled: true
#       authorization_endpoint: "https://accounts.google.com/o/oauth2/v2/auth"
#       device_authorization_endpoint: "https://oauth2.googleapis.com/device/code"
#       token_endpoint: "https://oauth2.googleapis.com/token"
#       user_info_endpoint: "https://openidconnect.googleapis.com/v1/userinfo"
#       resource_indicators:
#         - "urn:magictunnel:mcp:google:*"
#         - "https://www.googleapis.com/*"
#         
#     microsoft:
#       client_id: "${MICROSOFT_CLIENT_ID}"
#       client_secret: "${MICROSOFT_CLIENT_SECRET}"
#       scopes: ["openid", "email", "profile", "https://graph.microsoft.com/user.read"]
#       oauth_enabled: true
#       device_code_enabled: true
#       authorization_endpoint: "https://login.microsoftonline.com/common/oauth2/v2.0/authorize"
#       device_authorization_endpoint: "https://login.microsoftonline.com/common/oauth2/v2.0/devicecode"
#       token_endpoint: "https://login.microsoftonline.com/common/oauth2/v2.0/token"
#       user_info_endpoint: "https://graph.microsoft.com/v1.0/me"
#       
#     # Custom headless-only provider (Device Code Flow only)
#     custom_headless:
#       client_id: "${CUSTOM_CLIENT_ID}"
#       client_secret: "${CUSTOM_CLIENT_SECRET}"
#       scopes: ["api:read", "api:write"]
#       oauth_enabled: false               # Disable browser-based OAuth
#       device_code_enabled: true          # Only Device Code Flow
#       device_authorization_endpoint: "https://auth.custom.com/device/code"
#       token_endpoint: "https://auth.custom.com/token"
#       user_info_endpoint: "https://api.custom.com/user"
# 
#   # Device Code Flow Configuration (RFC 8628)
#   device_code_flow:
#     default_polling_interval_seconds: 5      # Default polling interval
#     max_polling_attempts: 360                # 30 minutes at 5-second intervals
#     default_timeout_seconds: 1800            # Device code expiration (30 minutes)
#     user_instruction_template: |
#       üîê Device Authorization Required
#       
#       Go to: {verification_uri}
#       Enter code: {user_code}
#       
#       Code expires in {expires_in_minutes} minutes.
#       MagicTunnel will continue automatically once authorized.
#     enable_verification_uri_complete: true   # Use complete URI when available
#     slow_down_increment_seconds: 5           # Increase interval on slow_down response
#     retry_on_network_error: true             # Retry on network failures
#     max_network_retries: 3                   # Max network retry attempts
# 
#   # API Key Configurations (with RBAC support)
#   api_keys:
#     - key_ref: "admin_key"
#       name: "Administrator Key"
#       key: "${MAGICTUNNEL_ADMIN_API_KEY}"
#       rbac_user_id: "admin"
#       rbac_roles: ["admin", "read", "write"]
#       expires_at: "2025-12-31T23:59:59Z"
#       active: true
#       
#     - key_ref: "github_api_key"  
#       name: "GitHub Integration Key"
#       key: "${GITHUB_API_KEY}"
#       rbac_user_id: "github_integration"
#       rbac_roles: ["read", "write"]
#       active: true
#       
#     - key_ref: "readonly_key"
#       name: "Read Only Access Key"
#       key: "${MAGICTUNNEL_READONLY_API_KEY}"
#       rbac_user_id: "readonly"
#       rbac_roles: ["read"]
#       active: true
# 
#   # Service Account Configurations
#   service_accounts:
#     github_service:
#       account_type: "personal_access_token"
#       credentials: "${GITHUB_PAT}"
#       rbac_user_id: "github_service"
#       rbac_roles: ["read", "write"]
#       provider_config:
#         provider: "github"
#         api_base_url: "https://api.github.com"
#         
#     google_service:
#       account_type: "service_key"
#       credentials: "${GOOGLE_SERVICE_ACCOUNT_KEY_JSON}"
#       rbac_user_id: "google_service"  
#       rbac_roles: ["read", "write"]
#       provider_config:
#         provider: "google"
#         project_id: "${GOOGLE_PROJECT_ID}"
#         
#     custom_app_service:
#       account_type: "application_credentials"
#       credentials: "${CUSTOM_APP_CREDENTIALS}"
#       rbac_user_id: "custom_app"
#       rbac_roles: ["read"]
# 
#   # OAuth 2.1 Security Enhancements  
#   oauth_2_1:
#     enforce_pkce: true                       # Require PKCE for all OAuth flows
#     code_challenge_method: "S256"            # Only S256 supported for security
#     require_state_parameter: true           # Require state parameter
#     state_length: 32                        # Length of generated state parameter
#     code_verifier_length: 128               # PKCE code verifier length (43-128)
#     token_validation_cache_ttl: 3600        # Cache token validation for 1 hour
#     user_info_cache_ttl: 1800               # Cache user info for 30 minutes
#     token_refresh_threshold: 300             # Refresh tokens if expire in 5 minutes
#     enable_refresh_token_rotation: true     # Rotate refresh tokens for security
# 
#   # Resource Indicators Configuration (RFC 8707)
#   resource_indicators:
#     enabled: true                           # Enable Resource Indicators support
#     default_resources:
#       - "https://api.magictunnel.io/mcp"
#       - "urn:magictunnel:mcp:*"
#       - "urn:magictunnel:tools:*"
#     default_audience:
#       - "magictunnel-mcp-server"
#       - "magictunnel-tools"
#     require_explicit_resources: false      # For backward compatibility
#     wildcard_matching: true                # Support wildcard in resource URIs
#     resource_validation_strict: false      # Allow unlisted resources (for flexibility)
#     
#   # Session Management and Persistence (Legacy - replaced by session_persistence)
#   session:
#     storage_backend: "memory"              # memory|redis|file|database
#     storage_path: "./data/sessions"        # For file backend
#     redis_url: "${REDIS_URL}"             # For redis backend  
#     database_url: "${DATABASE_URL}"       # For database backend
#     session_ttl: 86400                    # Session TTL (24 hours)
#     refresh_threshold: 3600               # Refresh if expires in 1 hour
#     cleanup_interval: 3600                # Cleanup expired sessions every hour
#     enable_persistent_sessions: true      # Persist sessions across restarts
#     session_cookie_secure: true          # Require HTTPS for session cookies
#     session_cookie_same_site: "strict"   # CSRF protection
# 
#   # Session Persistence Configuration (OAuth 2.1 Phase 2) - RECOMMENDED
#   session_persistence:
#     enabled: true                           # Enable OAuth 2.1 session persistence system (env: MAGICTUNNEL_SESSION_PERSISTENCE_ENABLED)
#     
#     # User Context Configuration (Phase 2.1)
#     user_context:
#       enabled: true                         # Enable user context identification (env: MAGICTUNNEL_USER_CONTEXT_ENABLED)
#       session_directory: "~/.magictunnel/sessions"  # Custom session directory (env: MAGICTUNNEL_CUSTOM_SESSION_DIR)
#       hostname_isolation: true              # Isolate sessions by hostname (env: MAGICTUNNEL_HOSTNAME_ISOLATION)
#       
#     # Token Storage Configuration (Phase 2.2)  
#     token_storage:
#       enabled: true                         # Enable secure token storage (env: MAGICTUNNEL_TOKEN_STORAGE_ENABLED)
#       storage_backend: "auto"               # auto|keychain|credential_manager|secret_service|filesystem (env: MAGICTUNNEL_TOKEN_STORAGE_BACKEND)
#       encryption_enabled: true              # Enable AES-256-GCM encryption for filesystem storage (env: MAGICTUNNEL_TOKEN_ENCRYPTION_ENABLED)
#       file_permissions: "0600"              # File permissions for token files (env: MAGICTUNNEL_TOKEN_FILE_PERMISSIONS)
#       max_tokens_per_provider: 10           # Maximum stored tokens per provider (env: MAGICTUNNEL_MAX_TOKENS_PER_PROVIDER)
#       token_cleanup_interval_hours: 24      # Cleanup expired tokens every N hours (env: MAGICTUNNEL_TOKEN_CLEANUP_INTERVAL)
#       
#     # Session Recovery Configuration (Phase 2.3)
#     session_recovery:
#       enabled: true                         # Enable automatic session recovery (env: MAGICTUNNEL_SESSION_RECOVERY_ENABLED)
#       auto_recovery_on_startup: true        # Recover sessions on application start (env: MAGICTUNNEL_SESSION_RECOVERY_STARTUP)
#       validation_interval_minutes: 60       # Validate active sessions every N minutes (env: MAGICTUNNEL_SESSION_VALIDATION_INTERVAL)
#       max_recovery_attempts: 3              # Maximum recovery attempts per token (env: MAGICTUNNEL_MAX_RECOVERY_ATTEMPTS)
#       token_validation_timeout_seconds: 30  # Timeout for token validation requests (env: MAGICTUNNEL_TOKEN_VALIDATION_TIMEOUT)
#       graceful_degradation: true            # Gracefully handle invalid/expired tokens (env: MAGICTUNNEL_GRACEFUL_DEGRADATION)
#       retry_failed_providers: true          # Retry failed providers after delay (env: MAGICTUNNEL_RETRY_FAILED_PROVIDERS)
#       
#     # Token Refresh Configuration (Phase 2.4)
#     token_refresh:
#       enabled: true                         # Enable automatic token refresh (env: MAGICTUNNEL_TOKEN_REFRESH_ENABLED)
#       refresh_threshold_minutes: 15         # Refresh tokens when they expire in N minutes (env: MAGICTUNNEL_TOKEN_REFRESH_THRESHOLD)
#       background_refresh_enabled: true      # Enable background refresh service (env: MAGICTUNNEL_BACKGROUND_REFRESH_ENABLED)
#       max_retry_attempts: 3                 # Maximum refresh retry attempts (env: MAGICTUNNEL_REFRESH_MAX_RETRY_ATTEMPTS)
#       retry_delay_base_seconds: 5           # Base delay for exponential backoff (env: MAGICTUNNEL_REFRESH_RETRY_DELAY_BASE)
#       concurrent_refresh_limit: 5           # Maximum concurrent refresh operations (env: MAGICTUNNEL_CONCURRENT_REFRESH_LIMIT)
#       refresh_queue_size: 100               # Maximum size of refresh queue (env: MAGICTUNNEL_REFRESH_QUEUE_SIZE)
#       enable_refresh_token_rotation: true   # Enable OAuth 2.1 refresh token rotation (env: MAGICTUNNEL_REFRESH_TOKEN_ROTATION)
# 
#   # Security and Monitoring Configuration
#   security:
#     enable_url_validation: true
#     trusted_domains:
#       - "github.com"
#       - "api.github.com"
#       - "accounts.google.com"
#       - "oauth2.googleapis.com"
#       - "login.microsoftonline.com"
#       - "graph.microsoft.com"
#     blocked_domains:
#       - "malicious-site.com"
#     rate_limiting:
#       enabled: true
#       max_auth_attempts_per_minute: 10
#       max_token_requests_per_minute: 60
#       max_device_code_requests_per_minute: 5
#       lockout_duration_minutes: 15
#       enable_progressive_delay: true
#     audit_logging:
#       enabled: true
#       log_level: "info"                   # debug|info|warn|error
#       log_successful_auth: true
#       log_failed_auth: true
#       log_token_exchanges: true
#       log_device_flow_events: true
#       log_session_events: true
#       log_rbac_decisions: true
#       audit_log_file: "./logs/auth-audit.log"
#       audit_log_rotation: true
#       max_audit_log_size_mb: 100
#       
#   # Thread-Safe Caching Configuration
#   caching:
#     enabled: true
#     auth_resolution_cache_size: 1000      # Cache size for auth resolution
#     auth_resolution_cache_ttl: 300        # 5 minutes
#     provider_validation_cache_ttl: 600    # 10 minutes
#     token_validation_cache_size: 5000     # Max cached token validations
#     user_info_cache_size: 1000           # Max cached user info
#     enable_cache_metrics: true           # Track cache hit/miss rates
#     cache_cleanup_interval: 1800         # Cleanup every 30 minutes

# =============================================================================
# MCP CLIENT CONFIGURATION
# =============================================================================
# Configuration for MCP client connections (used when connecting to external MCP servers)
mcp_client:
  connect_timeout_secs: 30      # Connection timeout in seconds
  request_timeout_secs: 60      # Request timeout in seconds
  max_reconnect_attempts: 5     # Maximum reconnection attempts
  reconnect_delay_secs: 5       # Delay between reconnection attempts
  auto_reconnect: true          # Enable automatic reconnection
  protocol_version: "2025-06-18" # MCP protocol version to use
  client_name: "magictunnel"    # Client name for MCP handshake (defaults to package name)
  client_version: "0.3.5"       # Client version for MCP handshake (defaults to package version)

# =============================================================================
# EXTERNAL MCP CONFIGURATION (Claude Desktop Format)
# =============================================================================
# Enable discovery and integration of external MCP servers using Claude Desktop's
# exact configuration format for maximum compatibility.
#
# MIGRATION NOTE: The legacy mcp_proxy, mcp_servers, and remote_mcp configurations
# have been removed. Use this external_mcp system instead.
external_mcp:
  enabled: true                     # Enable external MCP discovery (env: EXTERNAL_MCP_ENABLED)
  config_file: "/Users/gouravd/Development/magicbeanbs100x/magictunnel/external-mcp-servers.yaml"  # Path to external MCP servers config file
  capabilities_output_dir: "/Users/gouravd/Development/magicbeanbs100x/magictunnel/capabilities/external-mcp"  # Where to generate capability files
  refresh_interval_minutes: 60      # How often to refresh capabilities (env: EXTERNAL_MCP_REFRESH_INTERVAL)

  # Container Configuration (for Docker/Podman MCP servers)
  containers:
    runtime: "docker"               # Container runtime: docker|podman (env: CONTAINER_RUNTIME)
    node_image: "node:18-alpine"    # Default Node.js image for MCP servers
    python_image: "python:3.11-alpine"  # Default Python image for MCP servers
    network_mode: "bridge"          # Container network mode
    run_args: ["--rm", "-i"]        # Additional container run arguments


  # Note: External MCP uses the global conflict_resolution configuration below

# =============================================================================
# GLOBAL CONFLICT RESOLUTION CONFIGURATION
# =============================================================================
# Configuration for resolving conflicts when tools from different sources have the same name
# This applies to conflicts between local tools and external MCP tools

conflict_resolution:
  # Strategy for resolving tool name conflicts
  # Options: local_first, proxy_first, first_found, reject, prefix
  strategy: "LocalFirst"         # Strategy: LocalFirst|ProxyFirst|FirstFound|Reject|Prefix (env: CONFLICT_RESOLUTION_STRATEGY)

  # Prefix for local tools when using prefix strategy
  local_prefix: "local"           # Prefix for local tools (env: CONFLICT_RESOLUTION_LOCAL_PREFIX)

  # Format for external/proxy tool prefixes when using prefix strategy
  # Use {server} placeholder for server name
  proxy_prefix_format: "{server}" # Format for external tool prefixes (env: CONFLICT_RESOLUTION_PROXY_PREFIX_FORMAT)

  # Whether to log conflict resolutions
  log_conflicts: true             # Log conflicts (env: CONFLICT_RESOLUTION_LOG_CONFLICTS)

  # Whether to include conflict metadata in tool definitions
  include_conflict_metadata: true # Include metadata (env: CONFLICT_RESOLUTION_INCLUDE_METADATA)

# =============================================================================
# SMART DISCOVERY CONFIGURATION
# =============================================================================
# Configuration for the Smart Tool Discovery system that provides intelligent
# tool selection based on natural language requests

smart_discovery:
  enabled: true                           # Enable smart discovery (env: SMART_DISCOVERY_ENABLED)
  tool_selection_mode: "hybrid"          # Tool selection mode: rule_based|llm_based|semantic_based|hybrid (env: SMART_DISCOVERY_MODE)
  default_confidence_threshold: 0.7       # Default confidence threshold for tool matching (env: SMART_DISCOVERY_THRESHOLD)
  max_tools_to_consider: 10               # Maximum number of tools to consider for matching (env: SMART_DISCOVERY_MAX_TOOLS)
  max_high_quality_matches: 3             # Maximum high-quality matches to collect before stopping processing (env: SMART_DISCOVERY_MAX_HIGH_QUALITY_MATCHES)
  high_quality_threshold: 0.95            # Confidence threshold for considering a match as high-quality (env: SMART_DISCOVERY_HIGH_QUALITY_THRESHOLD)
  use_fuzzy_matching: true                # Enable fuzzy matching for tool names (env: SMART_DISCOVERY_FUZZY)
  enable_sequential_mode: true            # Enable sequential mode for multi-step workflows (default: true) (env: SMART_DISCOVERY_SEQUENTIAL_MODE)

  # LLM Tool Selection Configuration (for llm_based mode)
  llm_tool_selection:
    enabled: true                         # Enable LLM-based tool selection (env: SMART_DISCOVERY_LLM_ENABLED)
    provider: "openai"                    # LLM provider: openai|anthropic|ollama (env: SMART_DISCOVERY_LLM_PROVIDER)
    model: "gpt-4o-mini"                  # Model name to use (env: SMART_DISCOVERY_LLM_MODEL)
    api_key: null                         # API key (set via api_key_env)
    api_key_env: "OPENAI_API_KEY"         # Environment variable for API key (env: SMART_DISCOVERY_LLM_API_KEY_ENV)
    base_url: null                        # Custom base URL (env: SMART_DISCOVERY_LLM_BASE_URL)
    timeout: 30                           # Request timeout in seconds (env: SMART_DISCOVERY_LLM_TIMEOUT)
    max_retries: 3                        # Maximum retries for failed requests (env: SMART_DISCOVERY_LLM_MAX_RETRIES)
    batch_size: 15                        # Batch size for processing tools (env: SMART_DISCOVERY_LLM_BATCH_SIZE)
    max_context_tokens: 4000              # Maximum context tokens to use (env: SMART_DISCOVERY_LLM_MAX_TOKENS)

  # LLM Parameter Mapping Configuration
  llm_mapper:
    enabled: true                         # Enable LLM parameter mapping (env: SMART_DISCOVERY_MAPPER_ENABLED)
    provider: "openai"                    # LLM provider: openai|anthropic|ollama (env: SMART_DISCOVERY_MAPPER_PROVIDER)
    model: "gpt-4o-mini"                  # Model name to use (env: SMART_DISCOVERY_MAPPER_MODEL)
    api_key_env: "OPENAI_API_KEY"         # Environment variable for API key (env: SMART_DISCOVERY_MAPPER_API_KEY_ENV)
    base_url: null                        # Custom base URL (env: SMART_DISCOVERY_MAPPER_BASE_URL)
    timeout: 30                           # Request timeout in seconds (env: SMART_DISCOVERY_MAPPER_TIMEOUT)
    max_retries: 3                        # Maximum retries for failed requests (env: SMART_DISCOVERY_MAPPER_MAX_RETRIES)

  # Cache Configuration
  cache:
    enabled: true                         # Enable caching (env: SMART_DISCOVERY_CACHE_ENABLED)
    max_tool_matches: 1000               # Maximum number of entries in tool matching cache
    tool_match_ttl: 3600                 # TTL for tool matching cache entries (seconds)
    max_llm_responses: 500               # Maximum number of entries in LLM response cache
    llm_response_ttl: 1800               # TTL for LLM response cache entries (seconds)
    max_registry_entries: 100            # Maximum number of entries in registry cache
    registry_ttl: 300                    # TTL for registry cache entries (seconds)

  # Fallback Configuration
  fallback:
    enabled: true                         # Enable fallback suggestions (env: SMART_DISCOVERY_FALLBACK_ENABLED)
    min_confidence_threshold: 0.3         # Minimum confidence for fallback suggestions (env: SMART_DISCOVERY_FALLBACK_MIN_CONFIDENCE)
    max_fallback_suggestions: 5           # Maximum number of fallback suggestions (env: SMART_DISCOVERY_FALLBACK_MAX_SUGGESTIONS)
    enable_fuzzy_fallback: true           # Enable fuzzy matching fallback (env: SMART_DISCOVERY_FALLBACK_FUZZY)
    enable_keyword_fallback: true         # Enable keyword-based fallback (env: SMART_DISCOVERY_FALLBACK_KEYWORDS)
    enable_category_fallback: true        # Enable category-based fallback (env: SMART_DISCOVERY_FALLBACK_CATEGORIES)
    enable_partial_match_fallback: true   # Enable partial match fallback (env: SMART_DISCOVERY_FALLBACK_PARTIAL)

  # Semantic Search Configuration
  semantic_search:
    enabled: true                         # Enable semantic search (env: SMART_DISCOVERY_SEMANTIC_ENABLED)
    model_name: "ollama:nomic-embed-text"   # Embedding model name - Options:
                                          # 
                                          # RECOMMENDED OPTIONS (fully working):
                                          # - "ollama:nomic-embed-text" (768-dim, Ollama server) - BEST FOR LOCAL DEVELOPMENT
                                          # - "openai:text-embedding-3-small" (1536-dim, OpenAI API) - BEST FOR PRODUCTION
                                          # - "external:api" (custom embedding API via EMBEDDING_API_URL) - CUSTOM SETUPS
                                          #
                                          # CLOUD MODELS (API key required):
                                          # - "openai:text-embedding-3-large" (3072-dim, OpenAI API) - PREMIUM QUALITY
                                          #
                                          # FALLBACK OPTIONS (deterministic hashing - not recommended for production):
                                          # - "all-MiniLM-L6-v2" (384-dim) - Uses hash-based fallback, not real embeddings
                                          # - "all-mpnet-base-v2" (768-dim) - Uses hash-based fallback, not real embeddings
                                          # - "local:/path/to/model" (custom model) - Uses hash-based fallback
                                          # 
                                          # SETUP INSTRUCTIONS:
                                          # For Ollama: ollama pull nomic-embed-text && export OLLAMA_BASE_URL=http://localhost:11434
                                          # For OpenAI: export OPENAI_API_KEY=your-key-here
                                          # For External: export EMBEDDING_API_URL=http://your-server:8080
                                          # 
                                          # Environment override: MAGICTUNNEL_SEMANTIC_MODEL
    similarity_threshold: 0.55             # Minimum similarity threshold for semantic matches (env: SMART_DISCOVERY_SEMANTIC_THRESHOLD)
    max_results: 10                       # Maximum number of semantic search results (env: SMART_DISCOVERY_SEMANTIC_MAX_RESULTS)
    
    # Persistent Storage Configuration
    storage:
      embeddings_file: "/Users/gouravd/Development/magicbeanbs100x/magictunnel/data/embeddings/tool_embeddings.bin"  # Binary file for embeddings storage
      metadata_file: "/Users/gouravd/Development/magicbeanbs100x/magictunnel/data/embeddings/tool_metadata.json"     # JSON file for tool metadata
      hash_file: "/Users/gouravd/Development/magicbeanbs100x/magictunnel/data/embeddings/content_hashes.json"        # JSON file for content hash validation
      backup_count: 3                     # Number of backup files to maintain
      auto_backup: true                   # Automatically backup embeddings on updates
      compression: true                   # Enable compression for storage files
    
    # Model Configuration
    model:
      cache_dir: "/Users/gouravd/Development/magicbeanbs100x/magictunnel/data/models"          # Directory to cache downloaded models (env: SMART_DISCOVERY_SEMANTIC_CACHE_DIR)
      device: "cpu"                       # Device to use: cpu|cuda|mps (env: SMART_DISCOVERY_SEMANTIC_DEVICE)
      max_sequence_length: 512            # Maximum sequence length for embeddings
      batch_size: 32                      # Batch size for embedding generation
      normalize_embeddings: true          # Normalize embeddings to unit vectors
      
    # Performance Configuration
    performance:
      lazy_loading: true                  # Load embeddings only when needed
      embedding_cache_size: 1000          # In-memory cache size for embeddings
      parallel_processing: true           # Enable parallel embedding generation
      worker_threads: 4                   # Number of worker threads for parallel processing

# =============================================================================
# MCP 2025-06-18 SAMPLING SERVICE CONFIGURATION
# =============================================================================
# Configuration for the Sampling service that enables structured LLM message generation
sampling:
  enabled: true                          # Enable sampling service (env: SAMPLING_ENABLED)
  default_sampling_strategy: "client_forwarded"  # Default sampling routing strategy
  
  # LLM Configuration for MagicTunnel-handled requests
  llm_config:
    provider: "openai"                   # LLM provider: openai|anthropic|ollama
    model: "gpt-4o-mini"                 # Model name to use
    api_key_env: "OPENAI_API_KEY"        # Environment variable for API key
    max_tokens: 4000                     # Maximum tokens allowed per request
    base_url: null                       # Custom base URL (optional)
    timeout: 30                          # Request timeout in seconds
    max_retries: 3                       # Maximum retries for failed requests

# =============================================================================
# MCP 2025-06-18 TOOL ENHANCEMENT SERVICE CONFIGURATION
# =============================================================================
# Configuration for the Tool Enhancement service that generates enhanced descriptions,
# keywords, and examples for tools using LLM-powered analysis
tool_enhancement:
  enabled: true                          # Enable tool enhancement service (env: TOOL_ENHANCEMENT_ENABLED)
  
  # LLM Configuration for Tool Enhancement
  llm_config:
    provider: "openai"                   # LLM provider: openai|anthropic|ollama (env: TOOL_ENHANCEMENT_LLM_PROVIDER)
    model: "gpt-4o-mini"                 # Model name to use (env: TOOL_ENHANCEMENT_LLM_MODEL)
    api_key_env: "OPENAI_API_KEY"        # Environment variable for API key (env: TOOL_ENHANCEMENT_LLM_API_KEY_ENV)
    api_base_url: null                   # Custom base URL (env: TOOL_ENHANCEMENT_LLM_BASE_URL)
    max_tokens: 4000                     # Maximum tokens per request (env: TOOL_ENHANCEMENT_LLM_MAX_TOKENS)
    temperature: 0.7                     # Temperature for creativity (env: TOOL_ENHANCEMENT_LLM_TEMPERATURE)

# =============================================================================
# MCP 2025-06-18 ELICITATION SERVICE CONFIGURATION
# =============================================================================
# Configuration for the Elicitation service that enables structured data collection
# NOTE: Currently only supports client_forwarded strategy (proxy passes requests to client)
elicitation:
  enabled: true                          # Enable elicitation service (env: ELICITATION_ENABLED)
  default_elicitation_strategy: "client_forwarded"  # Default elicitation routing strategy

# =============================================================================
# VISIBILITY CONFIGURATION
# =============================================================================
visibility:
  # Hide individual tools when smart discovery is enabled (default: true for Smart Discovery Mode)
  # When true, only smart_tool_discovery tool is exposed to MCP clients
  hide_individual_tools: true     # Hide individual tools (env: VISIBILITY_HIDE_INDIVIDUAL_TOOLS)

  # Only expose smart_tool_discovery tool (default: true for Ultimate Smart Discovery Mode)
  # This is the ultimate Smart Tool Discovery mode - single tool interface
  expose_smart_discovery_only: true # Smart discovery only (env: VISIBILITY_EXPOSE_SMART_DISCOVERY_ONLY)

  # Allow individual tools to override hidden setting (default: true)
  # When false, global settings take precedence over tool-level hidden flags
  allow_override: true            # Allow tool-level overrides (env: VISIBILITY_ALLOW_OVERRIDE)

  # Default hidden state for new tools (default: true in Smart Discovery Mode)
  default_hidden: true            # Default hidden state for new tools (env: VISIBILITY_DEFAULT_HIDDEN)

# =============================================================================
# ENHANCEMENT STORAGE CONFIGURATION
# =============================================================================
# Configuration for storing enhanced tool descriptions and metadata
enhancement_storage:
  storage_dir: "./storage/enhanced_tools"  # Directory to store enhanced tool data (env: ENHANCEMENT_STORAGE_DIR)
  max_storage_mb: 512                      # Maximum storage size in MB (env: ENHANCEMENT_STORAGE_MAX_MB)
  enable_versioning: true                  # Enable versioning of enhancements (env: ENHANCEMENT_STORAGE_VERSIONING)
  auto_load_on_startup: true               # Auto-load enhancements on startup (env: ENHANCEMENT_STORAGE_AUTO_LOAD)
  
  # Cleanup policy for old enhancement data
  cleanup_policy:
    max_age_days: 90                       # Maximum age in days before cleanup (env: ENHANCEMENT_CLEANUP_MAX_AGE_DAYS)
    max_versions_per_tool: 5               # Maximum versions to keep per tool (env: ENHANCEMENT_CLEANUP_MAX_VERSIONS)
    cleanup_on_startup: true               # Clean up old data on startup (env: ENHANCEMENT_CLEANUP_ON_STARTUP)

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
logging:
  level: "info"            # Log level: debug|info|notice|warning|error|critical|alert|emergency (env: MCP_LOG_LEVEL)
  format: "text"           # Log format: json|text (env: MCP_LOG_FORMAT)
  file: null               # Optional: log to file instead of stdout
